{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/quarknova/miniconda3/envs/ml/lib/python3.7/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /opt/conda/conda-bld/pytorch_1607370156314/work/c10/cuda/CUDAFunctions.cpp:100.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import scipy as sp\n",
    "import math\n",
    "import string\n",
    "import re\n",
    "import pickle\n",
    "import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = \"gilf/french-camembert-postag-model\"\n",
    "\n",
    "model = transformers.AutoModelForTokenClassification.from_pretrained(source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = transformers.AutoTokenizer.from_pretrained(source)\n",
    "\n",
    "classifier = transformers.pipeline('ner', model=model, tokenizer=tokenizer, grouped_entities=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampleText = \"Le persan (autonyme : fārsī, ou pārsī) est une langue indo-européenne. C'est la langue officielle et majoritaire de l'Iran (centre, centre-sud, nord-est), de l'Afghanistan et du Tadjikistan. Le persan est une langue notable mais minoritaire à Bahreïn, en Irak, à Oman, au Qatar et aux Émirats arabes unis. Le dari, dialecte du persan, également appelé persan afghan ou persan oriental, est une langue officielle en Afghanistan ; il est parlé également en Iran et au Pakistan. De même, le tadjik, autre dialecte du persan, est la langue officielle du Tadjikistan et également parlé au Kirghizistan, au Turkménistan, en Ouzbékistan, et dans une moindre mesure au Kazakhstan. Le persan ou l’une de ses langues-sœurs est également parlé en Azerbaïdjan, en Russie et en Ouzbékistan (minorité tadjike). Jadis, du XVIe au XIXe siècle, il fut la langue officielle de l'Empire moghol. Le persan fait partie du groupe indo-iranien de la famille des langues indo-européennes. C'est une langue du type « sujet-objet-verbe ». Les langues persanes s’écrivent surtout au moyen de l'alphabet arabo-persan, variante de l'alphabet arabe, bien qu'elles n'aient aucune parenté avec la langue arabe, dont elles diffèrent tant sur le plan de la grammaire que de la phonologie. Au Tadjikistan, en Russie, en Azerbaïdjan et en Ouzbékistan, le tadjik s’écrit au moyen de l'alphabet cyrillique.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r embs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r token_to_idx\n",
    "%store -r idx_to_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here, we are building the graph structure for TextRank\n",
    "\n",
    "class Graph(object):\n",
    "    def __init__(self, n, E, dir=False):\n",
    "        self.n = n\n",
    "        self.E = E\n",
    "        self.score = [1 for i in range(n)]\n",
    "        self.inV = [[] for i in range(n)]\n",
    "        self.outV = [[] for i in range(n)]\n",
    "        \n",
    "        for e in E:\n",
    "            w = 1 if len(e) == 2 else e[2]\n",
    "            \n",
    "            self.inV[e[1]].append([e[0], w])\n",
    "            self.outV[e[0]].append([e[1], w])\n",
    "            if not dir:\n",
    "                self.inV[e[0]].append([e[1], w])\n",
    "                self.outV[e[1]].append([e[0], w])\n",
    "    \n",
    "    #Part 9\n",
    "    def textRank(self, d=0.85):\n",
    "        maxShift = 1\n",
    "        \n",
    "        while(maxShift >= 1e-4):\n",
    "            newScore = [(1-d) for i in range(self.n)]\n",
    "            for i in range(self.n):\n",
    "                for l, j in enumerate(self.inV[i]):\n",
    "                    newScore[i] += d * self.score[j[0]] * self.inV[i][l][1]/sum([k[1] for k in self.outV[j[0]]])\n",
    "            maxShift = max([abs(self.score[k] - newScore[k]) for k in range(self.n)])\n",
    "            self.score = newScore\n",
    "        return self.score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(sentence, removeDup=False):\n",
    "    rawData = classifier(sentence)\n",
    "    cleanedData = [word for word in rawData if (word['entity_group'] in ['ADJ', 'ADJWH', 'ET', 'NC', 'NPP'])]\n",
    "    tokens = [word['word'] for word in cleanedData]\n",
    "    return (list(dict.fromkeys(tokens)) if removeDup else tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Variables\n",
    "\n",
    "n = 32 #Dimensionality of the sentence vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sampleText' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-6a17e7d12199>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtextRank\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m \u001b[0msentenceRank\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msampleText\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'sampleText' is not defined"
     ]
    }
   ],
   "source": [
    "#Here, we are coding the functions for the main computations\n",
    "\n",
    "#Part 1\n",
    "def sentenceSplit(t): #Takes a text, returns sentences\n",
    "    sl = re.split(\"(?<=[.?!])\", t) #Sentence splitting\n",
    "    sl = [s if (s == \"\" or s[-1] not in [\" \", \"\\n\"]) else s[:-1] for s in sl]\n",
    "    sl = [s if (s == \"\" or s[0] not in [\" \", \"\\n\"]) else s[1:] for s in sl]\n",
    "    sl = [s for s in sl if len(tokenize(s)) != 0] #Cleaning up\n",
    "    return sl\n",
    "\n",
    "#Parts 2 and 3\n",
    "#def sentenceParse(s): #Takes a sentence, returns a tree\n",
    "    #return st\n",
    "    \n",
    "#Part 4\n",
    "def vectorize(s): #Takes a sentence, returns a vector\n",
    "    tokens = [t for t in tokenize(s) if t in idx_to_token]\n",
    "    sv = np.array(embs[0])-np.array(embs[0])+np.sum(np.array([embs[token_to_idx[t]] for t in tokens]), 0)\n",
    "    return np.squeeze(sv)\n",
    "\n",
    "#Part 5\n",
    "def topicVector(sv): #Takes sentence vectors, returns a topic vector\n",
    "    return np.average(sv, 0)\n",
    "\n",
    "#Part 6\n",
    "def cleanVectors(sv): #Takes sentence vectors, returns cleaned sentence and topic vectors\n",
    "    #Performing PCA\n",
    "    svCentered = np.array([[i - np.average(s) for i in s] for s in sv])\n",
    "    cov = np.cov(svCentered, rowvar=False)\n",
    "    vals, vects = np.linalg.eig(cov)\n",
    "    sortedEigs = sorted([(vals[i], vects[i]) for i in range(len(vals))], key = lambda x : x[0])\n",
    "    principalComponent = sortedEigs[-1][1]\n",
    "    #Cleaning the vectors\n",
    "    svCleaned = np.array([s - (s.dot(principalComponent) * principalComponent) for s in sv])\n",
    "    topic = topicVector(sv)\n",
    "    topicCleaned = topic - (topic.dot(principalComponent) * principalComponent)\n",
    "    return svCleaned, topicCleaned\n",
    "\n",
    "#Part 7\n",
    "def sentenceDist(i, j, sv, tv): #Takes sentence numbers and cleaned vectors, returns a distance\n",
    "    cos_sim = nn.CosineSimilarity()\n",
    "    return min(cos_sim(torch.Tensor([sv[i]]), torch.Tensor([sv[j]])), 2*cos_sim(torch.Tensor([tv]), torch.Tensor([sv[j]])))\n",
    "    #args = sv[i].extend(sv[j]).extend(tv).append(sv[i].dot(sv[j]))\n",
    "    #return distNet(args)\n",
    "\n",
    "#Part 8 (+9)\n",
    "def sentenceRank(t): #Takes a text, returns sentence rankings\n",
    "    sl = sentenceSplit(t)\n",
    "    sv = [vectorize(s) for s in sl]\n",
    "    sv, tv = cleanVectors(sv)\n",
    "    \n",
    "    n = len(sl) #Graph construction\n",
    "    gs = []\n",
    "    for i in range(n):\n",
    "        for j in range(i): #The graph is undirected, we avoid duplicates\n",
    "            dist = sentenceDist(i, j, sv, tv)[0].item()\n",
    "            gs.append([i, j, 1/max(dist, 1e-3)])\n",
    "    g = Graph(n, gs, dir=False)\n",
    "    return list(zip(sl, g.textRank()))\n",
    "\n",
    "sentenceRank(sampleText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le persan (autonyme : fārsī, ou pārsī) est une langue indo-européenne. C'est la langue officielle et majoritaire de l'Iran (centre, centre-sud, nord-est), de l'Afghanistan et du Tadjikistan. Le persan est une langue notable mais minoritaire à Bahreïn, en Irak, à Oman, au Qatar et aux Émirats arabes unis. Le dari, dialecte du persan, également appelé persan afghan ou persan oriental, est une langue officielle en Afghanistan ; il est parlé également en Iran et au Pakistan. De même, le tadjik, autre dialecte du persan, est la langue officielle du Tadjikistan et également parlé au Kirghizistan, au Turkménistan, en Ouzbékistan, et dans une moindre mesure au Kazakhstan. Le persan ou l’une de ses langues-sœurs est également parlé en Azerbaïdjan, en Russie et en Ouzbékistan (minorité tadjike). Jadis, du XVIe au XIXe siècle, il fut la langue officielle de l'Empire moghol. Le persan fait partie du groupe indo-iranien de la famille des langues indo-européennes. C'est une langue du type « sujet-objet-verbe ». Les langues persanes s’écrivent surtout au moyen de l'alphabet arabo-persan, variante de l'alphabet arabe, bien qu'elles n'aient aucune parenté avec la langue arabe, dont elles diffèrent tant sur le plan de la grammaire que de la phonologie. Au Tadjikistan, en Russie, en Azerbaïdjan et en Ouzbékistan, le tadjik s’écrit au moyen de l'alphabet cyrillique.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/quarknova/miniconda3/envs/ml/lib/python3.7/site-packages/ipykernel_launcher.py:42: ComplexWarning: Casting complex values to real discards the imaginary part\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "De même, le tadjik, autre dialecte du persan, est la langue officielle du Tadjikistan et également parlé au Kirghizistan, au Turkménistan, en Ouzbékistan, et dans une moindre mesure au Kazakhstan. Jadis, du XVIe au XIXe siècle, il fut la langue officielle de l'Empire moghol. Le persan fait partie du groupe indo-iranien de la famille des langues indo-européennes. Au Tadjikistan, en Russie, en Azerbaïdjan et en Ouzbékistan, le tadjik s’écrit au moyen de l'alphabet cyrillique.\n"
     ]
    }
   ],
   "source": [
    "#Part 10\n",
    "def summarize(t, length):\n",
    "    unsortedList = [(k[0], k[1], i) for i, k in enumerate(sentenceRank(t))]\n",
    "    sortedList = sorted(unsortedList, key=(lambda k: -k[1])) #Sorting\n",
    "    sentences = [s for i, s in enumerate(sortedList) if (i == 0 or s[0] != sortedList[i-1][0])] #Removing duplicates\n",
    "    \n",
    "    summarySentences = []\n",
    "    l = 0\n",
    "    for s in sentences:\n",
    "        l += len(tokenize(s[0]))\n",
    "        if(l > length):\n",
    "            break\n",
    "        summarySentences.append(s)\n",
    "    summary = [s[0] for s in sorted(summarySentences, key=(lambda k: k[2]))]\n",
    "    return \" \".join(summary)\n",
    "\n",
    "print(sampleText)\n",
    "print(summarize(sampleText, 50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
