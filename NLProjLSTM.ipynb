{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import scipy as sp\n",
    "import math\n",
    "import string\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 3 #Maximum number of children from a node, 3 is to account for x-bar schemas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMNode(object): #Cf. https://arxiv.org/pdf/1503.00075.pdf\n",
    "    def __init__(m, n): #Defines a node of input size m and output size n, analogous to a layer of a neural network\n",
    "        #What I'd like to implement would be to have a set of weights/bias for each type of sentence node and x-bar schema, allowing for fine-tuning without overfitting on every given node\n",
    "        self.m = m #Input dimensions\n",
    "        self.n = n #Output dimensions\n",
    "        self.w = np.random.rand(4, m, n) #Weights\n",
    "        self.u = np.random.rand(3, N, n, n) #Recurrence weights\n",
    "        self.uf = np.random.rand(N, N, n, n) #Recurrence openness weights\n",
    "        self.b = np.random.rand(4, n) #Bias\n",
    "        self.c = np.zeros(n) #Memory cell\n",
    "        self.h = np.zeros(n) #Hidden state\n",
    "    \n",
    "    def forward(x, h, c): #h is the array of the hidden states of upstream nodes, c the array of the memory cells\n",
    "        K = len(h) #The number of upstream nodes, at most N\n",
    "        \n",
    "        i = sig(np.dot(w[0], x) + np.sum([np.dot(u[0][i], h[i]) for i in range(K)]) + b[0]) #Sig to be replaced by the proper function\n",
    "        f = np.array([sig(np.dot(w[1], x) + np.sum([np.dot(uf[i][j], h[j]) for i in range(K)]) + b[1]) for j in range(K)])\n",
    "        o = sig(np.dot(w[0], x) + np.sum([np.dot(u[2][i], h[i]) for i in range(K)]) + b[0])\n",
    "        self.u = np.tanh(np.dot(w[3], x) + np.sum([np.dot(u[3][i], h[i]) for i in range(K)]) + b[3])\n",
    "        \n",
    "        self.c = np.multiply(i, self.u) + np.sum(np.multiply(f, c), axis=0)\n",
    "        self.h = np.multiply(o, np.tanh(self.c))\n",
    "\n",
    "class LSTM(object):\n",
    "    def __init__(nodes, links):\n",
    "        self.nodes = nodes #We assume that nodes are sorted downstream\n",
    "        self.links = links\n",
    "        self.upstream = [[] for n in nodes]\n",
    "        \n",
    "        for l in links:\n",
    "            self.upstream[l[0]].append(l[1])\n",
    "    \n",
    "    def forward(x):\n",
    "        for n in nodes:\n",
    "            forward(x, [nodes[m].h for m in upstream[n]], [nodes[m].c for m in upstream[n]])\n",
    "        return nodes[-1].h"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
